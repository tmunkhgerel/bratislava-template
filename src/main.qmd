---
title: "On the Reproducibility of Plausible Results"
# date automatically set to today
date: "`r Sys.Date()`"
# see ./_quarto.yml to change other options
# (e.g., author, rendering format (pdf by default), ...)
# these options apply to all .qmd files in the project 
---

```{r}
#| label: setup
#| echo: false

# load packages; hide startup messages for pretty output
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(modelsummary))

# load functions
source("./src/lib/io.R")

# read data; we know the column types, so we can suppress the messages

df <- read_csv("./data/data.csv", show_col_types = FALSE)
```

# Introduction

Reproducibility is now widely recognized as a central concern in empirical research. Recent work by @lambda2024defaults emphasizes that many irreproducible results stem not from flawed methods, but from undocumented defaults, missing metadata, and fragile workflows. Here, we argue that even _entirely plausible_ results may _fail to reproduce_ when computational environments are not explicitly specified.

This paper follows that perspective. Using a simple dataset on student outcomes [@student_exam_scores_kaggle], we estimate a conventional regression model and present the results in tabular and graphical form (Section @sec-results). The goal is not to uncover new empirical insights, but to provide a compact, transparent example that can be reproduced end-to-end with minimal effort.

# Data

We convert percentages to proportions. [@tbl-data-cleaning] shows a summary of the data.

```{r}
#| label: tbl-data-cleaning
#| tbl-cap: Data summary

# Data transformation: convert percentages to proportions
df <- df |> mutate(
  attendance_percent = attendance_percent / 100,
  previous_scores = previous_scores / 100,
  exam_score = exam_score / 100
)

# Show summary statistics for the dataset
datasummary_skim(
  df,
  fun_numeric = list(
    Mean = Mean,
    SD = SD
  ),
  escape = FALSE
)
```

# Results {#sec-results}

```{r}
#| label: analysis

models <- list(
  lm(exam_score ~ previous_scores, data = df),
  lm(exam_score ~ hours_studied + sleep_hours + attendance_percent + previous_scores, data = df)
)
```

We estimate the following linear model:

$$
\text{exam}_i = \beta_0 + \beta_1 \text{hours\_studied}_i + \beta_2 \text{sleep\_hours}_i
+ \beta_3 \text{attendance}_i + \beta_4 \text{previous\_scores}_i + \varepsilon_i,
$$

where $\varepsilon_i$ denotes an idiosyncratic error term. @tbl-table reports the estimated coefficients, and @fig-figure visualizes them with 95% confidence intervals.

```{r}
#| label: tbl-table
#| tbl-cap: Regression of Exam Scores on Study Inputs

modelsummary(models)
```

```{r}
#| label: fig-figure
#| fig-cap: Coefficient Estimates with Confidence Intervals

modelplot(models)
```

The results are broadly consistent with intuition. In particular:

1. prior performance is strongly predictive of current exam outcomes,
2. attendance is positively associated with scores, and
3. study time has a modest but precisely estimated effect.

For completeness, we note three features of the empirical setup:

- __Measurement.__ All variables are measured at the individual level.
- __Illustration.__ The sample is purely illustrative.
- __Linearity.__ The specification is intentionally linear.

![An External Image Included for Demonstration Purposes](../assets/static/dk.jpg){#fig-donkeykong}

Figure @fig-donkeykong provides an external visual reference included solely to demonstrate the handling of figures.

# References
